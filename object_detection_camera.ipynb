{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "venv",
   "display_name": "venv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import common.const as const\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "COCO17_HUMAN_POSE_KEYPOINTS = const.COCO17_HUMAN_POSE_KEYPOINTS\n",
    "\n",
    "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "model_display_name = 'EfficientDet_D4_1024x1024'\n",
    "model_handle = './models/knownese/' + model_display_name\n",
    "\n",
    "print('Selected model:' + model_display_name)\n",
    "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# ## Loading the selected model from TensorFlow Hub\n",
    "# Here we just need the model handle that was selected and use the Tensorflow Hub library to load it to memory.\n",
    "start_time = time.time()\n",
    "\n",
    "print('loading model...')\n",
    "hub_model = hub.load(model_handle)\n",
    "print('model loaded!')\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_offset = 0\n",
    "results = None\n",
    "result = None\n",
    "keypoints = None\n",
    "keypoint_scores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_numpy_array(img):\n",
    "    image = Image.fromarray(img)\n",
    "    (im_width, im_height) = image.size\n",
    "    # print('Width: {}'.format(im_width))\n",
    "    # print('Height: {}'.format(im_height))\n",
    "    return np.array(image).reshape(\n",
    "        (1, im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "source": [
    "cap = cv2.VideoCapture(0)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "while(cap.isOpened()):\n",
    "    isDetect = False\n",
    "    start_time = time.time()\n",
    "\n",
    "    _, image_np = cap.read()\n",
    "    image_np = image_to_numpy_array(image_np)\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('a')):\n",
    "        isDetect = True\n",
    "        results = hub_model(image_np)\n",
    "\n",
    "        # different object detection models have additional results\n",
    "        result = {key: value.numpy() for key, value in results.items()}\n",
    "\n",
    "        # Use keypoints if available in detections\n",
    "        if 'detection_keypoints' in result:\n",
    "            keypoints = result['detection_keypoints'][0]\n",
    "            keypoint_scores = result['detection_keypoint_scores'][0]\n",
    "    elif (cv2.waitKey(1) & 0xFF == ord('r')):\n",
    "        result = None\n",
    "\n",
    "    if(result is not None):\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections[0],\n",
    "            result['detection_boxes'][0],\n",
    "            (result['detection_classes'][0] + label_id_offset).astype(int),\n",
    "            result['detection_scores'][0],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.30,\n",
    "            agnostic_mode=False,\n",
    "            keypoints=keypoints,\n",
    "            keypoint_scores=keypoint_scores,\n",
    "            keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS,\n",
    "            line_thickness=1)\n",
    "\n",
    "    # show img\n",
    "    cv2.imshow('Capturing after detection', image_np_with_detections[0])\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    if(isDetect):\n",
    "        print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "print('Stoped!')"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "while(cap.isOpened()):\n",
    "    start_time = time.time()\n",
    "\n",
    "    _, image_np = cap.read()\n",
    "    image_np = image_to_numpy_array(image_np)\n",
    "    image_np_with_mask = image_np.copy()\n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('a')):\n",
    "        results = hub_model(image_np)\n",
    "\n",
    "        # different object detection models have additional results\n",
    "        # all of them are explained in the documentation\n",
    "        result = {key: value.numpy() for key, value in results.items()}\n",
    "\n",
    "        if 'detection_masks' in result:\n",
    "            # we need to convert np.arrays to tensors\n",
    "            detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n",
    "            detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n",
    "\n",
    "            # Reframe the the bbox mask to the image size.\n",
    "            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                        detection_masks, detection_boxes,\n",
    "                        image_np.shape[1], image_np.shape[2])\n",
    "            detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                                tf.uint8)\n",
    "            result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    elif (cv2.waitKey(1) & 0xFF == ord('r')):\n",
    "        result = None\n",
    "\n",
    "    if(result is not None):\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_mask[0],\n",
    "            result['detection_boxes'][0],\n",
    "            (result['detection_classes'][0] + label_id_offset).astype(int),\n",
    "            result['detection_scores'][0],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.30,\n",
    "            agnostic_mode=False,\n",
    "            instance_masks=result.get('detection_masks_reframed', None),\n",
    "            line_thickness=2)\n",
    "\n",
    "    # show img\n",
    "    cv2.imshow('Capturing after detection', image_np_with_mask[0])\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('a')):\n",
    "        print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "print('Stoped!')"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}